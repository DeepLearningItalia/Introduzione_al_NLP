{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook we will implement a simple neural network to classify texts.\n",
        "\n",
        "The dataset we will use is Offensive Language Identification (OLID), where short texts in English are labeled for offensiveness. We focus on subtask A: binary classification of offensiveness."
      ],
      "metadata": {
        "id": "YTKyjcXGmBHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://sites.google.com/site/offensevalsharedtask/olid/OLIDv1.0.zip\n",
        "!unzip OLIDv1.0.zip"
      ],
      "metadata": {
        "id": "OsfrOamEWebM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8693dd15-6ec6-4110-cea0-82f9fa4901a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-05 15:59:20--  https://sites.google.com/site/offensevalsharedtask/olid/OLIDv1.0.zip\n",
            "Resolving sites.google.com (sites.google.com)... 142.250.4.100, 142.250.4.139, 142.250.4.138, ...\n",
            "Connecting to sites.google.com (sites.google.com)|142.250.4.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://sites.google.com/site/offensevalsharedtask/olid/OLIDv1.0.zip?attredirects=0 [following]\n",
            "--2022-10-05 15:59:20--  https://sites.google.com/site/offensevalsharedtask/olid/OLIDv1.0.zip?attredirects=0\n",
            "Reusing existing connection to sites.google.com:443.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://ef80a887-a-62cb3a1a-s-sites.googlegroups.com/site/offensevalsharedtask/olid/OLIDv1.0.zip?attachauth=ANoY7cocD70A6ODZ7QNzL2qwxeZgr3Yt23gQqfaZkpXFQUhKNhhZUo8CLSVUXjeM8Z7RBlJw7OpCedmi0ouVz6F-CBUHLgKyUuNbdq_8WR7pKcQE0L26JxWeLa5uiinJShWBpXE9S7DinygoxRTesiaYWVIVFMx0IOSvht2CtpcSByDwzhNoAxQGv81XFioKK12MsKAYAPLl0sqWWuyB9U6xuGEiy2pxI-UfLEmkZdyzF0R4P2vxTzs%3D&attredirects=0 [following]\n",
            "--2022-10-05 15:59:20--  https://ef80a887-a-62cb3a1a-s-sites.googlegroups.com/site/offensevalsharedtask/olid/OLIDv1.0.zip?attachauth=ANoY7cocD70A6ODZ7QNzL2qwxeZgr3Yt23gQqfaZkpXFQUhKNhhZUo8CLSVUXjeM8Z7RBlJw7OpCedmi0ouVz6F-CBUHLgKyUuNbdq_8WR7pKcQE0L26JxWeLa5uiinJShWBpXE9S7DinygoxRTesiaYWVIVFMx0IOSvht2CtpcSByDwzhNoAxQGv81XFioKK12MsKAYAPLl0sqWWuyB9U6xuGEiy2pxI-UfLEmkZdyzF0R4P2vxTzs%3D&attredirects=0\n",
            "Resolving ef80a887-a-62cb3a1a-s-sites.googlegroups.com (ef80a887-a-62cb3a1a-s-sites.googlegroups.com)... 142.251.10.137, 2404:6800:4003:c0f::89\n",
            "Connecting to ef80a887-a-62cb3a1a-s-sites.googlegroups.com (ef80a887-a-62cb3a1a-s-sites.googlegroups.com)|142.251.10.137|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 874644 (854K) [application/zip]\n",
            "Saving to: ‘OLIDv1.0.zip’\n",
            "\n",
            "OLIDv1.0.zip        100%[===================>] 854.14K   649KB/s    in 1.3s    \n",
            "\n",
            "2022-10-05 15:59:23 (649 KB/s) - ‘OLIDv1.0.zip’ saved [874644/874644]\n",
            "\n",
            "Archive:  OLIDv1.0.zip\n",
            "  inflating: olid-annotation.txt     \n",
            "  inflating: olid-training-v1.0.tsv  \n",
            "  inflating: README.txt              \n",
            "  inflating: labels-levela.csv       \n",
            "  inflating: labels-levelb.csv       \n",
            "  inflating: labels-levelc.csv       \n",
            "  inflating: testset-levelc.tsv      \n",
            "  inflating: testset-levelb.tsv      \n",
            "  inflating: testset-levela.tsv      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "data_train = []\n",
        "labels_train = []\n",
        "\n",
        "with open(\"olid-training-v1.0.tsv\") as f:\n",
        "    reader = csv.DictReader(f, delimiter=\"\\t\")\n",
        "    for row in reader:\n",
        "        words = [word.lower() for word in word_tokenize(row[\"tweet\"])]\n",
        "        data_train.append(words)\n",
        "        labels_train.append(row[\"subtask_a\"])\n",
        "\n",
        "data_test = []\n",
        "labels_test = []\n",
        "with open(\"testset-levela.tsv\") as f:\n",
        "    reader = csv.DictReader(f, delimiter=\"\\t\")\n",
        "    for row in reader:\n",
        "        words = [word.lower() for word in word_tokenize(row[\"tweet\"])]\n",
        "        data_test.append(words)\n",
        "\n",
        "with open(\"labels-levela.csv\") as f:\n",
        "    reader = csv.DictReader(f, fieldnames=[\"id\", \"label\"])\n",
        "    for row in reader:\n",
        "        labels_test.append(row[\"label\"])\n"
      ],
      "metadata": {
        "id": "yHd0sKA2XwyZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fac7ad65-f682-40ca-b379-7ba1cce80447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use Keras' tokenizer only to compute the vocabulary on the training set. Sentences are truncated at 100 tokens and padding is added for shortes sentences."
      ],
      "metadata": {
        "id": "JaUGuWVzpN6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# transform the sentences into vectors\n",
        "tokenizer = Tokenizer(filters='', lower=True, split=' ')\n",
        "tokenizer.fit_on_texts(data_train)\n",
        "word_index = tokenizer.word_index\n",
        "X_train = tokenizer.texts_to_matrix(data_train)\n",
        "X_train = pad_sequences(X_train, 100, padding='post', truncating='post')\n",
        "\n",
        "# encode the labels\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(labels_train)\n",
        "y_train = encoder.transform(labels_train)\n",
        "\n",
        "# vectorize the test set\n",
        "X_test = tokenizer.texts_to_matrix(data_test)\n",
        "X_test = pad_sequences(X_test, 100, padding='post', truncating='post')\n",
        "y_test = encoder.transform(labels_test)\n"
      ],
      "metadata": {
        "id": "txQLn6TrVFjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The neural network has a first layer where the embeddings are input. They are then concatenated by the Flatten layer and passed on a smaller fully connected hidden layer. The output layer is one neuron with sigmoid activation for binary classification (offensive/not offensive)."
      ],
      "metadata": {
        "id": "Ga5Ph1p1pymp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S40nnahGU_82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8052556f-4965-461e-9850-451ca85f6ac5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 300)          6444300   \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 30000)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 50)                1500050   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 50)                0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 50)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,944,401\n",
            "Trainable params: 7,944,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "745/745 [==============================] - 9s 7ms/step - loss: 0.6375 - accuracy: 0.6615 - val_loss: 0.6297 - val_accuracy: 0.6677\n",
            "Epoch 2/10\n",
            "745/745 [==============================] - 5s 7ms/step - loss: 0.6268 - accuracy: 0.6689 - val_loss: 0.6264 - val_accuracy: 0.6579\n",
            "Epoch 3/10\n",
            "745/745 [==============================] - 5s 7ms/step - loss: 0.6232 - accuracy: 0.6673 - val_loss: 0.6293 - val_accuracy: 0.6601\n",
            "Epoch 4/10\n",
            "745/745 [==============================] - 5s 7ms/step - loss: 0.6234 - accuracy: 0.6680 - val_loss: 0.6257 - val_accuracy: 0.6586\n",
            "Epoch 5/10\n",
            "745/745 [==============================] - 5s 7ms/step - loss: 0.6203 - accuracy: 0.6692 - val_loss: 0.6256 - val_accuracy: 0.6586\n",
            "Epoch 6/10\n",
            "745/745 [==============================] - 5s 7ms/step - loss: 0.6185 - accuracy: 0.6707 - val_loss: 0.6248 - val_accuracy: 0.6579\n",
            "Epoch 7/10\n",
            "745/745 [==============================] - 5s 7ms/step - loss: 0.6192 - accuracy: 0.6687 - val_loss: 0.6252 - val_accuracy: 0.6571\n",
            "Epoch 8/10\n",
            "745/745 [==============================] - 5s 7ms/step - loss: 0.6171 - accuracy: 0.6707 - val_loss: 0.6267 - val_accuracy: 0.6563\n",
            "Epoch 9/10\n",
            "745/745 [==============================] - 5s 7ms/step - loss: 0.6168 - accuracy: 0.6695 - val_loss: 0.6241 - val_accuracy: 0.6571\n",
            "Epoch 10/10\n",
            "745/745 [==============================] - 5s 7ms/step - loss: 0.6159 - accuracy: 0.6711 - val_loss: 0.6252 - val_accuracy: 0.6563\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense, Dropout, Embedding, Flatten\n",
        "import tensorflow as tf\n",
        "\n",
        "# create the models\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index)+1, 300, input_shape=(100,)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(50, input_shape=(X_train.shape[1],)))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "                  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "                  metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                        batch_size=16,\n",
        "                        epochs=10,\n",
        "                        shuffle=True,\n",
        "                        validation_split=0.1,\n",
        "                        verbose=1\n",
        "                        )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scikit-learn has useful functions to provide evaluation metrics as precision, recall and F1-score."
      ],
      "metadata": {
        "id": "pujzoSZYqBrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "pred = [int(x>=0.5) for x in model.predict(X_test)]\n",
        "print (classification_report(y_test, pred))"
      ],
      "metadata": {
        "id": "qgYZiDUScZW1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2edb8adf-e7b3-405c-bfd2-6a60403ed655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.98      0.84       620\n",
            "           1       0.54      0.05      0.10       240\n",
            "\n",
            "    accuracy                           0.72       860\n",
            "   macro avg       0.64      0.52      0.47       860\n",
            "weighted avg       0.68      0.72      0.63       860\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try to initialize the weights of the first layer with pre-trained embeddings from GloVe."
      ],
      "metadata": {
        "id": "SZ_cfMoRqFS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "import numpy as np\n",
        "\n",
        "glove2word2vec(\"glove.6B.300d.txt\", \"glove_gensim.6B.300d.txt\")\n",
        "embedding_model=KeyedVectors.load_word2vec_format(\"glove_gensim.6B.300d.txt\",binary=False)"
      ],
      "metadata": {
        "id": "nPZIGPnZgDk4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85ce73a3-c455-42b0-a0e7-9625c69c103a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-05 16:17:52--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-10-05 16:17:52--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.13MB/s    in 2m 40s  \n",
            "\n",
            "2022-10-05 16:20:34 (5.13 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    try:\n",
        "        embedding_vector = embedding_model[word]\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    except:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        continue\n"
      ],
      "metadata": {
        "id": "JhSDaCK7iMLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The embedding layer can be set to be trainable, or the weights can be kept frozen."
      ],
      "metadata": {
        "id": "yd48OgjuqPzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index)+1, 300, input_shape=(100,), weights=[embedding_matrix], trainable=False))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(50, input_shape=(X_train.shape[1],)))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "                  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "                  metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                        batch_size=16,\n",
        "                        epochs=10,\n",
        "                        shuffle=True,\n",
        "                        validation_split=0.1,\n",
        "                        verbose=1\n",
        "                        )"
      ],
      "metadata": {
        "id": "hxv1cnNIiOm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d340cc59-3f47-417e-ba0a-314e9a7c629d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 100, 300)          6444300   \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 30000)             0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 50)                1500050   \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 50)                0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,944,401\n",
            "Trainable params: 1,500,101\n",
            "Non-trainable params: 6,444,300\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "745/745 [==============================] - 5s 5ms/step - loss: 0.6324 - accuracy: 0.6596 - val_loss: 0.6281 - val_accuracy: 0.6616\n",
            "Epoch 2/10\n",
            "745/745 [==============================] - 2s 3ms/step - loss: 0.6224 - accuracy: 0.6657 - val_loss: 0.6196 - val_accuracy: 0.6639\n",
            "Epoch 3/10\n",
            "745/745 [==============================] - 2s 3ms/step - loss: 0.6169 - accuracy: 0.6668 - val_loss: 0.6168 - val_accuracy: 0.6609\n",
            "Epoch 4/10\n",
            "745/745 [==============================] - 2s 3ms/step - loss: 0.6136 - accuracy: 0.6708 - val_loss: 0.6160 - val_accuracy: 0.6699\n",
            "Epoch 5/10\n",
            "745/745 [==============================] - 2s 3ms/step - loss: 0.6080 - accuracy: 0.6740 - val_loss: 0.6139 - val_accuracy: 0.6707\n",
            "Epoch 6/10\n",
            "745/745 [==============================] - 3s 3ms/step - loss: 0.6037 - accuracy: 0.6790 - val_loss: 0.6155 - val_accuracy: 0.6654\n",
            "Epoch 7/10\n",
            "745/745 [==============================] - 2s 3ms/step - loss: 0.6000 - accuracy: 0.6811 - val_loss: 0.6105 - val_accuracy: 0.6662\n",
            "Epoch 8/10\n",
            "745/745 [==============================] - 2s 3ms/step - loss: 0.5959 - accuracy: 0.6863 - val_loss: 0.6129 - val_accuracy: 0.6715\n",
            "Epoch 9/10\n",
            "745/745 [==============================] - 2s 3ms/step - loss: 0.5919 - accuracy: 0.6866 - val_loss: 0.6090 - val_accuracy: 0.6715\n",
            "Epoch 10/10\n",
            "745/745 [==============================] - 3s 3ms/step - loss: 0.5867 - accuracy: 0.6909 - val_loss: 0.6123 - val_accuracy: 0.6715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = [int(x>=0.5) for x in model.predict(X_test)]\n",
        "print (classification_report(y_test, pred))"
      ],
      "metadata": {
        "id": "v1CVwCKnjfgQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c247454-6bcb-470a-fc82-3a5abfab04c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.97      0.84       620\n",
            "           1       0.58      0.09      0.16       240\n",
            "\n",
            "    accuracy                           0.73       860\n",
            "   macro avg       0.66      0.53      0.50       860\n",
            "weighted avg       0.69      0.73      0.65       860\n",
            "\n"
          ]
        }
      ]
    }
  ]
}